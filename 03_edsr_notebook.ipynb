{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKjkelmWm_Go"
      },
      "source": [
        "# **Imports & Iperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIc_lShoRR6N"
      },
      "outputs": [],
      "source": [
        "import tf_keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import main.utilities.utils as us\n",
        "import main.models.III_EDSR.architectures.architectures_edsr as arcs\n",
        "\n",
        "from tf_keras.layers import *\n",
        "from tf_keras.optimizers import *\n",
        "from tf_keras.utils import plot_model\n",
        "from tf_keras.preprocessing.image import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Iperparametri** \\\n",
        "Questi sono gli Iperparametri che possiamo decidere noi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEvR28o6oFyK"
      },
      "outputs": [],
      "source": [
        "# SuperRes\n",
        "BATCH_SIZE  = 16\n",
        "SCALE       = 4\n",
        "\n",
        "# DataSet\n",
        "LABEL_SIZE  = 96\n",
        "\n",
        "# Model\n",
        "EPOCHS = 50\n",
        "\n",
        "# Random Seed\n",
        "SEED        = 42\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM0zGWjEFanI"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQaYl52sTx23"
      },
      "outputs": [],
      "source": [
        "# Download DIV2K from TF Datasets\n",
        "# Using bicubic 4x degradation type\n",
        "div2k_data = tfds.image.Div2k(config=\"bicubic_x4\")\n",
        "div2k_data.download_and_prepare()\n",
        "\n",
        "# Taking train data from div2k_data object\n",
        "train = div2k_data.as_dataset(split=\"train\", as_supervised=True)\n",
        "train_cache = train.cache()\n",
        "# Validation data\n",
        "val = div2k_data.as_dataset(split=\"validation\", as_supervised=True)\n",
        "val_cache = val.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQnfbVHY6nT3"
      },
      "source": [
        "**Visualize Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "054f751qD-xM"
      },
      "outputs": [],
      "source": [
        "len(train), len(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSsVtoWScJIh"
      },
      "source": [
        "# **Create Dataset & Preprocess Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGpZ4E_T3DU"
      },
      "outputs": [],
      "source": [
        "def dataset_object(dataset_cache, training=True):\n",
        "  ds = dataset_cache\n",
        "\n",
        "  # Random Crops\n",
        "  ds = ds.map(\n",
        "      lambda lowres, highres: us.random_crop(lowres, highres, hr_crop_size=LABEL_SIZE, scale=SCALE),\n",
        "      num_parallel_calls=4,\n",
        "  )\n",
        "\n",
        "  # Augment Data\n",
        "  if training:\n",
        "    ds = ds.map(us.random_rotate, num_parallel_calls=4)\n",
        "    ds = ds.map(us.flip_left_right, num_parallel_calls=4)\n",
        "\n",
        "  # Batching Data\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # Repeating Data, so that cardinality if dataset becomes infinte\n",
        "  if training:\n",
        "      ds = ds.repeat()\n",
        "\n",
        "  # prefetching allows later images to be prepared while the current image is being processed\n",
        "  ds = ds.prefetch(buffer_size=BATCH_SIZE // 2)\n",
        "  return ds\n",
        "\n",
        "train_ds = dataset_object(train_cache, training=True)\n",
        "val_ds = dataset_object(val_cache, training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgAKVSfc7ESZ"
      },
      "source": [
        "**Visualize the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxKK-ry3T6lf"
      },
      "outputs": [],
      "source": [
        "lowres, highres = next(iter(train_ds))\n",
        "\n",
        "# High Resolution Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(highres[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(highres[i].shape)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Low Resolution Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(lowres[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(lowres[i].shape)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9vFgZ55A2DK"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alZRS7pWU9vl"
      },
      "source": [
        "**1. Create the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASyOdfon4kWD"
      },
      "outputs": [],
      "source": [
        "model = arcs.EDSR_Vanilla(num_filters=64, num_of_residual_blocks=16)\n",
        "model._name = (\"EDSR_Vanilla_fit50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Compile the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scegliamo quale Loss e quale Optimizer assegnare al Modello\n",
        "\n",
        "my_loss = \"mae\"\n",
        "my_opt = Adam(\n",
        "    learning_rate=schedules.PiecewiseConstantDecay(\n",
        "            boundaries=[5000], values=[0.0001, (0.0001 - 0.00005)]\n",
        "    )\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=my_loss,\n",
        "    optimizer=my_opt,\n",
        "    metrics=[us.PSNR_metric, us.SSIM_metric]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eseguiamo il Plot del Modello\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhBetcS5em1T"
      },
      "source": [
        "**3. Fit the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TensorBoard Callbacks\n",
        "tb_callback = tf_keras.callbacks.TensorBoard(log_dir=(\"logs/\" + str(model._name)), histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cHaNJYSCF31"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fit\n",
        "model.fit(train_ds, epochs=EPOCHS, steps_per_epoch=200, validation_data=val_ds, callbacks=[tb_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] Image Super-Resolution Using EDSR and WDSR - \"https://sumittagadiya.medium.com/image-super-resolution-using-edsr-and-wdsr-f4de0b00e039\"\n",
        "[2] Enhanced Deep Residual Networks for single-image super-resolution - \"https://keras.io/examples/vision/edsr/\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pKjkelmWm_Go",
        "WM0zGWjEFanI",
        "LSsVtoWScJIh"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
