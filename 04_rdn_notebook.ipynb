{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSIfS4-UjG1N"
      },
      "source": [
        "# **Imports & Iperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFSc3Hwoh9HY"
      },
      "outputs": [],
      "source": [
        "import tf_keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import main.utilities.utils as us\n",
        "import main.models.IV_RDN.architectures.architectures_rdn as arcs\n",
        "\n",
        "from tf_keras.layers import *\n",
        "from tf_keras.optimizers import Adam\n",
        "from tf_keras.losses import MeanAbsoluteError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Iperparametri** \\\n",
        "Questi sono gli Iperparametri che possiamo decidere noi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIfSZryzjKmA"
      },
      "outputs": [],
      "source": [
        "# SuperRes\n",
        "BATCH_SIZE   = 16\n",
        "SCALE        = 2\n",
        "\n",
        "# DataSet\n",
        "LABEL_SIZE  = 64\n",
        "\n",
        "# Model\n",
        "TRAINING_STEPS = 50000\n",
        "STEPSxEPOCHS = 1000\n",
        "EPOCHS = TRAINING_STEPS // STEPSxEPOCHS\n",
        "\n",
        "\n",
        "# Random Seed\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "SEED        = 42\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM0zGWjEFanI"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQaYl52sTx23"
      },
      "outputs": [],
      "source": [
        "# Download DIV2K from TF Datasets\n",
        "# Using bicubic 4x degradation type\n",
        "div2k_data = tfds.image.Div2k(config=\"bicubic_x2\")\n",
        "div2k_data.download_and_prepare()\n",
        "\n",
        "# Taking train data from div2k_data object\n",
        "train = div2k_data.as_dataset(split=\"train\", as_supervised=True)\n",
        "# Validation data\n",
        "val = div2k_data.as_dataset(split=\"validation\", as_supervised=True)\n",
        "\n",
        "train_cache = train.cache()\n",
        "val_cache = val.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQnfbVHY6nT3"
      },
      "source": [
        "**Visualize Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aYkv2fYlim6"
      },
      "outputs": [],
      "source": [
        "samples = train.take(2)\n",
        "ls = []\n",
        "for sample in samples:\n",
        "  lr = sample[0]\n",
        "  hr = sample[1]\n",
        "  ls.append(lr)\n",
        "  ls.append(hr)\n",
        "us.plot_images(ls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Create Dataset & Preprocess Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGpZ4E_T3DU"
      },
      "outputs": [],
      "source": [
        "def dataset_object(dataset_cache, training=True):\n",
        "  ds = dataset_cache\n",
        "\n",
        "  # Random Crops\n",
        "  ds = ds.map(\n",
        "      lambda lowres, highres: us.random_crop(lowres, highres, hr_crop_size=LABEL_SIZE, scale=SCALE),\n",
        "      num_parallel_calls=AUTOTUNE,\n",
        "  )\n",
        "\n",
        "  # Augment Data\n",
        "  if training:\n",
        "    ds = ds.map(us.random_rotate, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.map(us.random_flip, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.map(us.random_lr_jpeg_noise, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Batching Data\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # Repeating Data, so that cardinality if dataset becomes infinte\n",
        "  if training:\n",
        "      ds = ds.repeat()\n",
        "\n",
        "  # prefetching allows later images to be prepared while the current image is being processed\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = dataset_object(train_cache, training=True)\n",
        "val_ds = dataset_object(val_cache, training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgAKVSfc7ESZ"
      },
      "source": [
        "**Visualize the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxKK-ry3T6lf"
      },
      "outputs": [],
      "source": [
        "lowres, highres = next(iter(train_ds))\n",
        "\n",
        "# High Resolution Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(3):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(highres[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(highres[i].shape)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Low Resolution Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(3):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(lowres[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(lowres[i].shape)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdmBf7OEo6_w"
      },
      "source": [
        "\n",
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Create the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = arcs.RDN_Vanilla()\n",
        "model._name = (\"RDN_Vanilla_fit50_lr\" + str(lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Compile the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djTAWAAe4FNi"
      },
      "outputs": [],
      "source": [
        "my_loss = MeanAbsoluteError();\n",
        "my_opt = Adam(learning_rate=lr);\n",
        "\n",
        "model.compile(\n",
        "    loss=my_loss,\n",
        "    optimizer=my_opt,\n",
        "    metrics=[us.PSNR_metric, us.SSIM_metric]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eseguiamo il Plot del Modello\n",
        "model.summary()\n",
        "us.plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Fit the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define TensorBoard Callbacks\n",
        "tb_callback = tf_keras.callbacks.TensorBoard(log_dir=(\"logs/\" + str(lr)), histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit\n",
        "model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, steps_per_epoch=STEPSxEPOCHS, callbacks=[tb_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] RDN-for-SR-by-keras - \"https://github.com/cjdsj/RDN-for-SR-by-keras/blob/main/model.py\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jSIfS4-UjG1N",
        "WM0zGWjEFanI",
        "LSsVtoWScJIh",
        "l_Scqw7EJPZR"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
