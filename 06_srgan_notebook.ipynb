{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSIfS4-UjG1N"
      },
      "source": [
        "# **Imports & Iperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFSc3Hwoh9HY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import main.utilities.utils as us\n",
        "import main.models.VI_SRGAN.architectures.architectures_srgan as arcs\n",
        "\n",
        "from tf_keras.layers import *\n",
        "from tf_keras.optimizers import Adam\n",
        "from tf_keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "from tf_keras.losses import MeanSquaredError, BinaryCrossentropy\n",
        "from tf_keras.applications.vgg19 import VGG19\n",
        "from tf_keras.models import Model\n",
        "from tf_keras.metrics import Mean\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Iperparametri** \\\n",
        "Questi sono gli Iperparametri che possiamo decidere noi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIfSZryzjKmA"
      },
      "outputs": [],
      "source": [
        "# SuperRes\n",
        "BATCH_SIZE   = 16\n",
        "SCALE        = 4\n",
        "\n",
        "# DataSet\n",
        "LABEL_SIZE  = 96\n",
        "\n",
        "# Model\n",
        "TRAINING_STEPS = 5000\n",
        "STEPSxEPOCHS = 1000\n",
        "EPOCHS = TRAINING_STEPS // STEPSxEPOCHS\n",
        "UPSAMPLESxSCALE = {\n",
        "    2: 1,\n",
        "    4: 2,\n",
        "    8: 3\n",
        "}\n",
        "\n",
        "# Random Seed\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "SEED        = 42\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM0zGWjEFanI"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQaYl52sTx23",
        "outputId": "965020fa-27f6-4260-ea3b-24611fb0a558"
      },
      "outputs": [],
      "source": [
        "# Download DIV2K from TF Datasets\n",
        "# Using bicubic 4x degradation type\n",
        "div2k_data = tfds.image.Div2k(config=\"bicubic_x4\")\n",
        "div2k_data.download_and_prepare()\n",
        "\n",
        "# Taking train data from div2k_data object\n",
        "train = div2k_data.as_dataset(split=\"train\", as_supervised=True)\n",
        "# Validation data\n",
        "val = div2k_data.as_dataset(split=\"validation\", as_supervised=True)\n",
        "\n",
        "train_cache = train.cache()\n",
        "val_cache = val.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQnfbVHY6nT3"
      },
      "source": [
        "**Visualize Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aYkv2fYlim6",
        "outputId": "c42f0550-be47-4c33-ee1e-baaff7a0fb1f"
      },
      "outputs": [],
      "source": [
        "samples = train.take(1)\n",
        "ls = []\n",
        "for sample in samples:\n",
        "  lr = sample[0]\n",
        "  hr = sample[1]\n",
        "  ls.append(lr)\n",
        "  ls.append(hr)\n",
        "us.plot_images(ls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSsVtoWScJIh"
      },
      "source": [
        "# **Create Dataset & Preprocess Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGpZ4E_T3DU"
      },
      "outputs": [],
      "source": [
        "def dataset_object(dataset_cache, training=True):\n",
        "  ds = dataset_cache\n",
        "\n",
        "  # Random Crops\n",
        "  ds = ds.map(\n",
        "      lambda lowres, highres: us.random_crop(lowres, highres, hr_crop_size=LABEL_SIZE, scale=SCALE),\n",
        "      num_parallel_calls=AUTOTUNE,\n",
        "  )\n",
        "\n",
        "  # Augment Data\n",
        "  if training:\n",
        "    ds = ds.map(us.random_rotate, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.map(us.random_flip, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.map(us.random_lr_jpeg_noise, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Batching Data\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # Repeating Data, so that cardinality if dataset becomes infinte\n",
        "  if training:\n",
        "      ds = ds.repeat()\n",
        "\n",
        "  # prefetching allows later images to be prepared while the current image is being processed\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = dataset_object(train_cache, training=True)\n",
        "val_ds = dataset_object(val_cache, training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgAKVSfc7ESZ"
      },
      "source": [
        "**Visualize the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "LxKK-ry3T6lf",
        "outputId": "3a7645a2-e498-42e5-dc81-958f57caaa19"
      },
      "outputs": [],
      "source": [
        "lowres, highres = next(iter(train_ds))\n",
        "\n",
        "# High Resolution Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(3):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(highres[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(highres[i].shape)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Low Resolution Images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(3):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(lowres[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(lowres[i].shape)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZrMYhK8cF8O"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdgHixb2dNqy"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BzNuqY9RoWT"
      },
      "outputs": [],
      "source": [
        "# - Compile Properties -\n",
        "# Optimizers\n",
        "learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])\n",
        "generator_optimizer = Adam(learning_rate=learning_rate)\n",
        "discriminator_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Losses\n",
        "binary_cross_entropy = BinaryCrossentropy()\n",
        "mean_squared_error = MeanSquaredError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-EWP4qoQ1wC",
        "outputId": "02974608-9e52-428e-865e-51e1b5c8e208"
      },
      "outputs": [],
      "source": [
        "# Load Generator\n",
        "#generator = Generator()                            | Default Generator\n",
        "#generator.load_weights(\"/content/generator.h5\")    |\n",
        "\n",
        "original_model = arcs.Generator()\n",
        "generator = arcs.SRResNet_DenseBlock(original_model)\n",
        "generator.load_weights(\"/content/SRResNet_DenseBlock_fit25_lr0.0005.h5\")\n",
        "\n",
        "\n",
        "# Create Discriminator\n",
        "discriminator = arcs.Discriminator(hr_crop_size=LABEL_SIZE)\n",
        "\n",
        "# Load VGG\n",
        "layer_5_4 = 20\n",
        "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
        "perceptual_model = Model(vgg.input, vgg.layers[layer_5_4].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d161FoiIaDTA"
      },
      "outputs": [],
      "source": [
        "# Create Instance of Sbuclassed Model\n",
        "gan = arcs.TrainingClassGAN(generator, discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOyt1YGQckBW"
      },
      "outputs": [],
      "source": [
        "# Compile the Model\n",
        "gan.compile(generator_optimizer, discriminator_optimizer, mean_squared_error, binary_cross_entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgiFqbBddMrX"
      },
      "source": [
        "**Custom Loop Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJQWMXPQrd1m",
        "outputId": "9c5b4bb7-57d8-438f-aa64-6244cec18f02"
      },
      "outputs": [],
      "source": [
        "perceptual_loss_metric = Mean()\n",
        "discriminator_loss_metric = Mean()\n",
        "\n",
        "tensor_psnr = tf.Variable(0.0)\n",
        "now = time.perf_counter()\n",
        "\n",
        "monitor_folder = \"srgan_bicubic_x4\"\n",
        "os.makedirs(monitor_folder, exist_ok=True)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n --- Start of Training Epoch {epoch + 1} ---\")\n",
        "    step = 0\n",
        "    for (x_batch, y_batch) in tqdm(train_ds, total=STEPSxEPOCHS):\n",
        "        step += 1\n",
        "        perceptual_loss, discriminator_loss = gan.train_step(x_batch, y_batch)\n",
        "        perceptual_loss_metric(perceptual_loss)\n",
        "        discriminator_loss_metric(discriminator_loss)\n",
        "        #print(f\"step = {step}\")\n",
        "        if(step >= STEPSxEPOCHS):\n",
        "            break;\n",
        "\n",
        "    psnr_values = []\n",
        "    for lr, hr in val_ds:\n",
        "        sr = generator.predict(lr)[0]\n",
        "        sr = tf.clip_by_value(sr, 0, 255)\n",
        "        sr = tf.round(sr)\n",
        "        sr = tf.cast(sr, tf.uint8)\n",
        "\n",
        "        psnr_value = us.PSNR_metric(hr, sr)[0]\n",
        "        psnr_values.append(psnr_value)\n",
        "        psnr = tf.reduce_mean(psnr_values)\n",
        "\n",
        "    image = Image.fromarray(sr.numpy())\n",
        "    image.save(f\"{monitor_folder}/{epoch + 1}.png\" )\n",
        "\n",
        "    duration = time.perf_counter() - now\n",
        "\n",
        "    now = time.perf_counter()\n",
        "\n",
        "    print(f'{epoch + 1}/{EPOCHS}, psnr = {psnr}, perceptual loss = {perceptual_loss_metric.result():.4f}, discriminator loss = {discriminator_loss_metric.result():.4f} ({duration:.2f}s)')\n",
        "\n",
        "    perceptual_loss_metric.reset_states()\n",
        "    discriminator_loss_metric.reset_states()\n",
        "\n",
        "    tensor_psnr.assign(psnr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERH-bJRhYPBj",
        "outputId": "3d158db7-2747-4161-e730-608c7f1a4b05"
      },
      "outputs": [],
      "source": [
        "# Save the Model\n",
        "generator.save(f\"/content/drive/MyDrive/GAN/GAN_LRs/DenseBlock/GAN_DenseBlock_fit5_lr0.0001.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] image-super-resolution - \"https://github.com/jlaihong/image-super-resolution\"\n",
        "[2] Implementing SRResnet/SRGAN Super-Resolution with Tensorflow - \"https://medium.com/analytics-vidhya/implementing-srresnet-srgan-super-resolution-with-tensorflow-89900d2ec9b2\"\n",
        "[3] Image Super Resolution: SRResNet and SRGAN TensorFlow 2 implementation and model intuition - \"https://www.youtube.com/watch?v=FwvTsx_dxn8&list=WL&index=18\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jSIfS4-UjG1N",
        "WM0zGWjEFanI",
        "LSsVtoWScJIh",
        "xQ2AO-ltMMz3",
        "enEe6zfFQhve",
        "1yafCs0EI4YR"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
